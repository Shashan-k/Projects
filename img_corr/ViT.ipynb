{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (B,C,H,W)\n",
    "# (B,num_vectors,vector_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(images, n_patches):\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    assert h == w, \"Patchify method is implemented for square images only\"\n",
    "\n",
    "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
    "    patch_size = h // n_patches\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                patches[idx, i * n_patches + j] = patch.flatten()\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViT(nn.Module):\n",
    "  def __init__(self, chw=(3,28, 28), n_patches=7):\n",
    "    # Super constructor\n",
    "    super(MyViT, self).__init__()\n",
    "\n",
    "    # Attributes\n",
    "    self.chw = chw # (C, H, W)\n",
    "    self.n_patches = n_patches\n",
    "\n",
    "    assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "    assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "\n",
    "  def forward(self, images):\n",
    "    patches = patchify(images, self.n_patches)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 49, 48])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  # Current model\n",
    "  model = MyViT(\n",
    "    chw=(3, 28, 28),\n",
    "    n_patches=7\n",
    "  )\n",
    "\n",
    "  x = torch.randn(7, 3, 28,28) # Dummy images\n",
    "  print(model(x).shape) # torch.Size([7, 49, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# from einops.layers.torch import Rearrange\n",
    "# import torch\n",
    "\n",
    "# class PatchEmbedding(nn.Module):\n",
    "#     def __init__(self, in_channels=3, patch_size=8, emb_size=128):\n",
    "#         self.patch_size = patch_size\n",
    "#         super().__init__()\n",
    "#         self.projection = nn.Sequential(\n",
    "#             Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_size, p2=patch_size),\n",
    "#             nn.Linear(patch_size * patch_size * in_channels, emb_size)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.projection(x)\n",
    "#         return x\n",
    "\n",
    "# sample_datapoint = torch.randn(2, 3, 144, 144)  # Example random image tensor\n",
    "# datapoint_shape = sample_datapoint.shape\n",
    "# print(\"Initial shape: \", datapoint_shape)\n",
    "\n",
    "# patch_embedding = PatchEmbedding()\n",
    "\n",
    "# embedding = patch_embedding(sample_datapoint)\n",
    "# #print(\"Patches shape: \", embedding.shape)\n",
    "\n",
    "# batch_size = embedding.shape[0]\n",
    "# patch_size = patch_embedding.patch_size\n",
    "\n",
    "# num_vectors = (datapoint_shape[2] // patch_size) * (datapoint_shape[3] // patch_size)\n",
    "\n",
    "# vector_dim = embedding.shape[2]\n",
    "# reshaped_embedding = embedding.view(batch_size, num_vectors, vector_dim)\n",
    "\n",
    "# print(\"Required_shape: \", reshaped_embedding.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
